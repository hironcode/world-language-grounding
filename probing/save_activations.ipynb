{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gLtv_XwbB8m5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import tqdm\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import ninjax as nj\n",
        "from pathlib import Path\n",
        "from typing import Tuple, List, Dict, Any\n",
        "from torch.utils.data import DataLoader\n",
        "import elements\n",
        "import jax.numpy as jnp\n",
        "import ruamel.yaml as yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_boTTXkCmao",
        "outputId": "40b052b2-cfc4-4fd1-e5d9-d8ac0af70516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjpLSnKgDyeC",
        "outputId": "19f083d8-3d98-4554-cdc4-ea8203ebdf52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (from -r ../dreamerv3/requirements.txt (line 1)) (14.0.1)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r ../dreamerv3/requirements.txt -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve6mDisECCRX"
      },
      "outputs": [],
      "source": [
        "!pip install elements\n",
        "!pip install ninjax\n",
        "!pip install crafter\n",
        "!pip install jax\n",
        "!pip install ale-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SrxCB9xeDsxt"
      },
      "outputs": [],
      "source": [
        "root = Path(os.getcwd()).parent\n",
        "os.sys.path.append(str(root))\n",
        "os.sys.path.append(str(root / \"dreamerv3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WkxCoz8LB8m7"
      },
      "outputs": [],
      "source": [
        "# import locals\n",
        "from models.agent_probe import Agent, sg\n",
        "from models.rssm_probe import Decoder\n",
        "from dreamerv3.agent import Agent as AgentOri\n",
        "from embodied.envs import crafter\n",
        "from embodied.jax import transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLxQIAnoB8m8"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGUf0OkfB8m8",
        "outputId": "2c4d06a2-0305-40b3-e882-1bf2c8c76a3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def load_config(argv=None):\n",
        "    # adaptation from dreamerv3/main.py\n",
        "    configs = elements.Path('./configs.yaml').read()\n",
        "    configs = yaml.YAML(typ='safe').load(configs)\n",
        "    parsed, other = elements.Flags(configs=['defaults']).parse_known(argv)\n",
        "    config = elements.Config(configs['defaults'])\n",
        "    for name in parsed.configs:\n",
        "        config = config.update(configs[name])\n",
        "    # config = elements.Flags(config).parse(other)\n",
        "    config = config.update(logdir=(\n",
        "        config.logdir.format(timestamp=elements.timestamp())))\n",
        "\n",
        "    if 'JOB_COMPLETION_INDEX' in os.environ:\n",
        "        config = config.update(replica=int(os.environ['JOB_COMPLETION_INDEX']))\n",
        "    print('Replica:', config.replica, '/', config.replicas)\n",
        "\n",
        "    logdir = elements.Path(config.logdir)\n",
        "    print('Logdir:', logdir)\n",
        "    print('Run script:', config.script)\n",
        "\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C9CtwhJ8B8m9"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path='./dataset/crafter') -> Tuple[List[Dict[str, np.ndarray]], List[Dict[str, np.ndarray]]]:\n",
        "    img_pos = []\n",
        "    img_epi = []\n",
        "\n",
        "    stats_files = os.listdir(path)\n",
        "    path = Path(path)\n",
        "    for file in stats_files:\n",
        "        with open(path / file, 'r') as f:\n",
        "            data = [json.loads(line) for line in f]\n",
        "\n",
        "        for d in data:\n",
        "            img_pos.append({\"image\": np.array(d['image']), 'pos': np.array(d['pos'])})\n",
        "            img_epi.append({\"image\": np.array(d['image']), 'episode': np.array(d['episode'])})\n",
        "\n",
        "    return img_pos, img_epi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zYF6NNyCB8m9"
      },
      "outputs": [],
      "source": [
        "def load_agent(agent, path_to_pkl=\"./models/agent.pkl\"):\n",
        "    path_to_pkl = Path(path_to_pkl)\n",
        "    with open(path_to_pkl, 'rb') as f:\n",
        "        weight = pickle.load(f)['agent']\n",
        "    print(\"Agent loaded from\", path_to_pkl)\n",
        "    print(\"Agent type:\", type(weight))\n",
        "    print(type(agent))\n",
        "    agent.load(weight)\n",
        "    print(type(agent))\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9eejPeJ9B8m-"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "def overwrite_func(agent):\n",
        "    # overwrite call function in decoder\n",
        "    new_dec_call = lambda carry, feat, reset, training, single=False: Decoder.__call__(agent.model.dec, carry, feat, reset, training, single=False)\n",
        "    # print(\"new_dec_call: \")\n",
        "    # lines = inspect.getsource(Decoder.__call__)\n",
        "    agent.model.dec.__call__ = new_dec_call\n",
        "\n",
        "    # overwrite policy function in agent\n",
        "    new_agent_policy = lambda carry, obs, mode='train': Agent.policy(agent.model, carry, obs, mode='train')\n",
        "    agent.model.policy = new_agent_policy\n",
        "\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zxYLCLL4WZXP"
      },
      "outputs": [],
      "source": [
        "def reconstruct_obs_dummy(img):\n",
        "    batch_size = img.shape[0]\n",
        "    obs = dict(\n",
        "        image=img,\n",
        "        reward=np.stack([np.float32(0) for _ in range(batch_size)]),\n",
        "        is_first=np.stack([False]*batch_size),\n",
        "        is_last=np.stack([False]*batch_size),\n",
        "        is_terminal=np.stack([False]*batch_size),\n",
        "    )\n",
        "    return obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KWlLerJneFot"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "def collect_activations(carry, obs, agent: Agent):\n",
        "    # what is carry?: weight?\n",
        "    # prevact = previous action\n",
        "    (enc_carry, dyn_carry, dec_carry, prevact) = carry\n",
        "    kw = dict(training=False, single=True)\n",
        "    reset = obs['is_first']\n",
        "\n",
        "    # editted\n",
        "    activations = {}\n",
        "\n",
        "    # what is tokens?\n",
        "    enc_carry, enc_entry, tokens = agent.enc(enc_carry, obs, reset, **kw)\n",
        "\n",
        "    # editted\n",
        "    activations['encoder'] = tokens\n",
        "\n",
        "    dyn_carry, dyn_entry, feat = agent.dyn.observe(\n",
        "        dyn_carry, tokens, prevact, reset, **kw)\n",
        "\n",
        "    # editted\n",
        "    activations['dynamic'] = feat\n",
        "\n",
        "    dec_entry = {}\n",
        "    # if dec_carry:\n",
        "    dec_carry, dec_entry, recons = agent.dec(dec_carry, feat, reset, **kw)\n",
        "\n",
        "    # editted\n",
        "    activations['decoder'] = recons['x']\n",
        "\n",
        "    # actor: linear transformation of RSSM feature into action space distribution\n",
        "    sample = lambda xs: jax.tree.map(lambda x: x.sample(nj.seed()), xs)\n",
        "    policy = agent.pol(agent.feat2tensor(feat), bdims=1)\n",
        "    act = sample(policy)\n",
        "\n",
        "    # editted\n",
        "    activations['policy'] = policy\n",
        "\n",
        "    out = {}\n",
        "    out['finite'] = elements.tree.flatdict(jax.tree.map(\n",
        "        lambda x: jnp.isfinite(x).all(range(1, x.ndim)),\n",
        "        dict(obs=obs, carry=carry, tokens=tokens, feat=feat, act=act)))\n",
        "    carry = (enc_carry, dyn_carry, dec_carry, act)\n",
        "    return carry, act, out, activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlGEFjvyB8m-"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVrFqyCfB8m-",
        "outputId": "7b94d9cc-43f0-497d-f3d8-67c787cd400b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Replica: 0 / 1\n",
            "Logdir: /root/logdir/20250112T234839\n",
            "Run script: test\n",
            "Observations\n",
            "  image            Space(uint8, shape=(64, 64, 3), low=0, high=255)\n",
            "  reward           Space(float32, shape=(), low=-inf, high=inf)\n",
            "  is_first         Space(bool, shape=(), low=False, high=True)\n",
            "  is_last          Space(bool, shape=(), low=False, high=True)\n",
            "  is_terminal      Space(bool, shape=(), low=False, high=True)\n",
            "Actions\n",
            "  action           Space(int32, shape=(), low=0, high=17)\n",
            "Extras\n",
            "  consec           Space(int32, shape=(), low=-2147483648, high=2147483647)\n",
            "  stepid           Space(uint8, shape=(20,), low=0, high=255)\n",
            "  dyn/deter        Space(float32, shape=(8192,), low=-inf, high=inf)\n",
            "  dyn/stoch        Space(float32, shape=(32, 64), low=-inf, high=inf)\n",
            "JAX devices (1): [cuda:0]\n",
            "Policy devices: cuda:0\n",
            "Train devices:  cuda:0\n",
            "Initializing parameters...\n"
          ]
        }
      ],
      "source": [
        "config = load_config()\n",
        "\n",
        "# environment\n",
        "SEED = 0\n",
        "TASK = \"reward\"\n",
        "INDEX = 0\n",
        "seed = hash((SEED, INDEX)) % (2 ** 32 - 1)\n",
        "env = crafter.Crafter(seed=seed, task=TASK)\n",
        "  # adaptation from dreamerv3/main.py\n",
        "notlog = lambda k: not k.startswith('log/')\n",
        "obs_space = {k: v for k, v in env.obs_space.items() if notlog(k)}\n",
        "act_space = {k: v for k, v in env.act_space.items() if k != 'reset'}\n",
        "\n",
        "env.close()\n",
        "\n",
        "# agent\n",
        "# adaptation from dreamerv3/main.py\n",
        "config = elements.Config(\n",
        "      **config.agent,\n",
        "      logdir=config.logdir,\n",
        "      seed=config.seed,\n",
        "      jax=config.jax,\n",
        "      batch_size=config.batch_size,\n",
        "      batch_length=config.batch_length,\n",
        "      replay_context=config.replay_context,\n",
        "      report_length=config.report_length,\n",
        "      replica=config.replica,\n",
        "      replicas=config.replicas,\n",
        "  )\n",
        "agentori = AgentOri(obs_space, act_space, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATA_D89oS5wA"
      },
      "outputs": [],
      "source": [
        "agentori = overwrite_func(agentori)\n",
        "\n",
        "pm, ps = agentori.policy_mirrored, agentori.policy_sharded\n",
        "tp, pp = agentori.train_params_sharding, agentori.policy_params_sharding\n",
        "_, ar = agentori.partition_rules\n",
        "shared_kwargs = {'use_shardmap': agentori.jaxcfg.use_shardmap}\n",
        "\n",
        "agentori._policy = transform.apply(\n",
        "    nj.pure(agentori.model.policy), agentori.policy_mesh,\n",
        "    (pp, pm, ps, ps), (ps, ps, ps), ar,\n",
        "    static_argnums=(4,), **shared_kwargs)\n",
        "\n",
        "TEST = \"./models/checkpoint_test.pkl\"\n",
        "agentori = load_agent(agentori, TEST)\n",
        "\n",
        "agent = agentori.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5SFR7iJB8m_"
      },
      "outputs": [],
      "source": [
        "# dataset\n",
        "img_pos, img_epi = load_dataset(\"./test/\")\n",
        "print(len(img_pos), len(img_epi))\n",
        "assert len(img_pos) == len(img_epi)\n",
        "\n",
        "BSIZE = config.batch_size\n",
        "dl_space = DataLoader(img_pos, batch_size=BSIZE, shuffle=True)\n",
        "dl_time = DataLoader(img_epi, batch_size=BSIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diH3qWDeB8nA"
      },
      "source": [
        "# Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4sMuCU_jy8t"
      },
      "outputs": [],
      "source": [
        "jax.config.update(\"jax_transfer_guard\", \"allow\")\n",
        "from ninjax import pure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWOswNKIB8nA"
      },
      "source": [
        "## spatial activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoZ8BbgvB8nA"
      },
      "outputs": [],
      "source": [
        "carry = agentori.init_policy(batch_size=BSIZE)\n",
        "\n",
        "path_to_save = Path('./dataset/act/')\n",
        "os.makedirs(path_to_save, exist_ok=True)\n",
        "\n",
        "images = []\n",
        "positions = []\n",
        "deters = []\n",
        "stochs = []\n",
        "logits = []\n",
        "encoders = []\n",
        "decoders = []\n",
        "policies = []\n",
        "\n",
        "dtype=jnp.uint8\n",
        "\n",
        "cpu = lambda x: jax.device_put(x, device=jax.devices('cpu')[0]).astype(dtype)\n",
        "cuda = lambda x: jax.device_put(x, device=jax.devices()[0]).astype(dtype)\n",
        "\n",
        "\n",
        "for idx, batch in enumerate(tqdm.tqdm(dl_space)):\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n",
        "    img = jnp.asarray(batch['image'].numpy())\n",
        "    pos = jnp.asarray(batch['pos'].numpy())\n",
        "    img = cuda(img)\n",
        "    pos = cuda(pos)\n",
        "    # img = jnp.asarray(img)\n",
        "    # pos = jnp.asarray(pos)\n",
        "\n",
        "    img = sg(img)\n",
        "    pos = sg(pos)\n",
        "\n",
        "    carry = sg(carry)\n",
        "    obs = reconstruct_obs_dummy(img)\n",
        "\n",
        "    carry, act, out, activations = agentori.policy(carry, obs)\n",
        "\n",
        "    deter = activations['dynamic']['deter']\n",
        "    stoch = activations['dynamic']['stoch']\n",
        "    logit = activations['dynamic']['logit']\n",
        "\n",
        "    deter = np.array(sg(deter))\n",
        "    stoch = np.array(sg(stoch))\n",
        "    logit = np.array(sg(logit))\n",
        "    enc = np.array(sg(activations['encoder']))\n",
        "    dec = np.array(sg(activations['decoder']))\n",
        "    pol = np.array(sg(activations['policy']))\n",
        "\n",
        "    print(deter.shape, stoch.shape, logit.shape, enc.shape, dec.shape, pol.shape)\n",
        "\n",
        "    images.append(img)\n",
        "    positions.append(pos)\n",
        "    deters.append(deter)\n",
        "    stochs.append(stoch)\n",
        "    logits.append(logit)\n",
        "    encoders.append(enc)\n",
        "    decoders.append(dec)\n",
        "    policies.append(pol)\n",
        "\n",
        "images = np.stack(images, axis=0)\n",
        "positions = np.stack(positions, axis=0)\n",
        "deters = np.stack(deters, axis=0)\n",
        "stochs = np.stack(stochs, axis=0)\n",
        "logits = np.stack(logits, axis=0)\n",
        "encoders = np.stack(encoders, axis=0)\n",
        "decoders = np.stack(decoders, axis=0)\n",
        "policies = np.stack(policies, axis=0)\n",
        "\n",
        "np.savez_compressed(\n",
        "    path_to_save / f'space.npz',\n",
        "    images=images,\n",
        "    positions=positions,\n",
        "    deters=deters,\n",
        "    stochs=stochs,\n",
        "    logits=logits,\n",
        "    encoders=encoders,\n",
        "    decoders=decoders,\n",
        "    policies=policies\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKNdkU3SB8nA"
      },
      "source": [
        "## temporal activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bboTaOZpB8nA"
      },
      "outputs": [],
      "source": [
        "carry = agent.init_policy(batch_size=BSIZE)\n",
        "\n",
        "path_to_save = Path('./dataset/act/')\n",
        "\n",
        "images = []\n",
        "positions = []\n",
        "deters = []\n",
        "stochs = []\n",
        "logits = []\n",
        "encoders = []\n",
        "decoders = []\n",
        "policies = []\n",
        "\n",
        "for idx, batch in enumerate(tqdm.tqdm(dl_time)):\n",
        "    img = batch['image'].numpy()\n",
        "    epi = batch['episode'].numpy()\n",
        "    img = sg(img)\n",
        "    epi = sg(epi)\n",
        "\n",
        "    assert type(img) == np.ndarray, type(img)\n",
        "    assert type(epi) == np.ndarray, type(epi)\n",
        "\n",
        "    carry = sg(carry)\n",
        "\n",
        "    carry, act, out, activations = agent(carry, img, training=False)\n",
        "\n",
        "    deter = activations['dynamic']['deter']\n",
        "    stoch = activations['dynamic']['stoch']\n",
        "    logit = activations['dynamic']['logit']\n",
        "\n",
        "    deter = np.array(sg(deter))\n",
        "    stoch = np.array(sg(stoch))\n",
        "    logit = np.array(sg(logit))\n",
        "    enc = np.array(sg(activations['encoder']))\n",
        "    dec = np.array(sg(activations['decoder']))\n",
        "    pol = np.array(sg(activations['policy']))\n",
        "\n",
        "    print(deter.shape, stoch.shape, logit.shape, enc.shape, dec.shape, pol.shape)\n",
        "\n",
        "    images.append(img)\n",
        "    positions.append(pos)\n",
        "    deters.append(deter)\n",
        "    stochs.append(stoch)\n",
        "    logits.append(logit)\n",
        "    encoders.append(enc)\n",
        "    decoders.append(dec)\n",
        "    policies.append(pol)\n",
        "\n",
        "images = np.stack(images, axis=0)\n",
        "positions = np.stack(positions, axis=0)\n",
        "deters = np.stack(deters, axis=0)\n",
        "stochs = np.stack(stochs, axis=0)\n",
        "logits = np.stack(logits, axis=0)\n",
        "encoders = np.stack(encoders, axis=0)\n",
        "decoders = np.stack(decoders, axis=0)\n",
        "policies = np.stack(policies, axis=0)\n",
        "\n",
        "np.savez_compressed(\n",
        "    path_to_save / f'time.npz',\n",
        "    images=images,\n",
        "    positions=positions,\n",
        "    deters=deters,\n",
        "    stochs=stochs,\n",
        "    logits=logits,\n",
        "    encoders=encoders,\n",
        "    decoders=decoders,\n",
        "    policies=policies\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrb4rTE9B8nA"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
