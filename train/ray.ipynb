{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvizdoom\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvizdoom\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgymnasium_wrapper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgymnasium_env_defns\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VizdoomScenarioEnv\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_env\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wrap_env, reward_wrap_env\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mray\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import vizdoom as vzd\n",
    "import skimage.transform\n",
    "from utils import _ObservationWrapper\n",
    "\n",
    "import vizdoom.gymnasium_wrapper  # noqa\n",
    "import vizdoom\n",
    "from vizdoom.gymnasium_wrapper.gymnasium_env_defns import VizdoomScenarioEnv\n",
    "from ray.tune.registry import register_env\n",
    "from utils import wrap_env, reward_wrap_env\n",
    "\n",
    "import ray\n",
    "from ray.rllib.algorithms.dreamerv3.dreamerv3 import DreamerV3Config\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (64, 64)\n",
    "FRAME_SKIP = 4\n",
    "\n",
    "class ObservationWrapper(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    ViZDoom environments return dictionaries as observations, containing\n",
    "    the main image as well other info.\n",
    "    The image is also too large for normal training.\n",
    "\n",
    "    This wrapper replaces the dictionary observation space with a simple\n",
    "    Box space (i.e., only the RGB image), and also resizes the image to a\n",
    "    smaller size.\n",
    "\n",
    "    NOTE: Ideally, you should set the image size to smaller in the scenario files\n",
    "          for faster running of ViZDoom. This can really impact performance,\n",
    "          and this code is pretty slow because of this!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, shape=IMAGE_SHAPE, frame_skip=FRAME_SKIP):\n",
    "        super().__init__(env)\n",
    "        self.image_shape = shape\n",
    "        # print('shape', shape)\n",
    "        self.image_shape_reverse = shape[::-1]\n",
    "        # print('image_shape_reverse', self.image_shape_reverse)\n",
    "        self.env.frame_skip = frame_skip\n",
    "\n",
    "        # Create new observation space with the new shape\n",
    "        # print('env.obs', env.observation_space)\n",
    "        num_channels = env.observation_space[\"screen\"].shape[-1]\n",
    "        new_shape = (self.image_shape[0], self.image_shape[1], num_channels)\n",
    "        # print('new_shape', new_shape)\n",
    "        self.observation_space = gym.spaces.Box(0, 255, shape=new_shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # print('observation[\"screen\"].shape', observation[\"screen\"].shape)\n",
    "        observation = cv2.resize(observation[\"screen\"], self.image_shape_reverse)\n",
    "        # print('obs.shape', observation.shape)\n",
    "        observation = observation.astype('float32')\n",
    "        # print('obs.shape', observation.shape)\n",
    "        return observation\n",
    "\n",
    "def wrap_env(env, config):\n",
    "    env = ObservationWrapper(env, shape=config['image_shape'], frame_skip=config['frame_skip'])\n",
    "    env = gym.wrappers.TransformReward(env, lambda r: r * 0.01)\n",
    "    return env\n",
    "\n",
    "def reward_wrap_env(env):\n",
    "    env = gym.wrappers.TransformReward(env, lambda r: r * 0.01)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(train_config):\n",
    "\n",
    "    # config \n",
    "\n",
    "    config = {\"scenario_file\": \"basic.cfg\"}\n",
    "    def env_creator(env_config):\n",
    "        return wrap_env(VizdoomScenarioEnv(**config), train_config)\n",
    "    register_env('vizdoom_env', env_creator)\n",
    "\n",
    "    # Create DreamerV3\n",
    "\n",
    "    num_cpus = int(ray.cluster_resources()['CPU'])\n",
    "    num_gpus = int(ray.cluster_resources()['GPU'])\n",
    "\n",
    "    num_learner_workers = num_gpus-1\n",
    "    num_gpus_per_learner_worker = 1\n",
    "    num_cpus_per_learner_workers = 1\n",
    "\n",
    "    config = (\n",
    "            DreamerV3Config()\n",
    "            .environment(\n",
    "                env='vizdoom_env',\n",
    "            )\n",
    "            .resources(\n",
    "                num_learner_workers=num_learner_workers,\n",
    "                num_gpus_per_learner_worker=1,\n",
    "                # num_cpus_for_local_worker=1,\n",
    "                num_cpus_per_learner_worker=num_cpus_per_learner_workers,\n",
    "            )\n",
    "            .rollouts(num_envs_per_worker=1, remote_worker_envs=False)\n",
    "            .training(\n",
    "                model_size=\"S\",\n",
    "                training_ratio=512,\n",
    "                batch_size_B=16*num_learner_workers,\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "    # run training\n",
    "    iteration_num = train_config['ray_iterations']\n",
    "\n",
    "    algo = config.build()\n",
    "    print('------ algo=', algo)\n",
    "    for iteration in tqdm(range(iteration_num)):\n",
    "        result = algo.train()\n",
    "        print('result.keys', result.keys())\n",
    "\n",
    "\n",
    "    # shutdown ray\n",
    "    ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
